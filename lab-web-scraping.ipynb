{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786",
   "metadata": {
    "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786"
   },
   "source": [
    "# Lab | Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8882fc-4815-4567-92fa-b4816358ba7d",
   "metadata": {
    "id": "ce8882fc-4815-4567-92fa-b4816358ba7d"
   },
   "source": [
    "Welcome to the \"Books to Scrape\" Web Scraping Adventure Lab!\n",
    "\n",
    "**Objective**\n",
    "\n",
    "In this lab, we will embark on a mission to unearth valuable insights from the data available on Books to Scrape, an online platform showcasing a wide variety of books. As data analyst, you have been tasked with scraping a specific subset of book data from Books to Scrape to assist publishing companies in understanding the landscape of highly-rated books across different genres. Your insights will help shape future book marketing strategies and publishing decisions.\n",
    "\n",
    "**Background**\n",
    "\n",
    "In a world where data has become the new currency, businesses are leveraging big data to make informed decisions that drive success and profitability. The publishing industry, much like others, utilizes data analytics to understand market trends, reader preferences, and the performance of books based on factors such as genre, author, and ratings. Books to Scrape serves as a rich source of such data, offering detailed information about a diverse range of books, making it an ideal platform for extracting insights to aid in informed decision-making within the literary world.\n",
    "\n",
    "**Task**\n",
    "\n",
    "Your task is to create a Python script using BeautifulSoup and pandas to scrape Books to Scrape book data, focusing on book ratings and genres. The script should be able to filter books with ratings above a certain threshold and in specific genres. Additionally, the script should structure the scraped data in a tabular format using pandas for further analysis.\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`. The function should scrape book data from the \"Books to Scrape\" website and return a `pandas` DataFrame with the following columns:\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "- A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`.\n",
    "- The function should return a DataFrame with the following columns:\n",
    "  - **UPC**: The Universal Product Code (UPC) of the book.\n",
    "  - **Title**: The title of the book.\n",
    "  - **Price (£)**: The price of the book in pounds.\n",
    "  - **Rating**: The rating of the book (1-5 stars).\n",
    "  - **Genre**: The genre of the book.\n",
    "  - **Availability**: Whether the book is in stock or not.\n",
    "  - **Description**: A brief description or product description of the book (if available).\n",
    "  \n",
    "You will execute this script to scrape data for books with a minimum rating of `4.0 and above` and a maximum price of `£20`. \n",
    "\n",
    "Remember to experiment with different ratings and prices to ensure your code is versatile and can handle various searches effectively!\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "- [Books to Scrape](https://books.toscrape.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519921d-5890-445b-9a33-934ed8ee378c",
   "metadata": {
    "id": "3519921d-5890-445b-9a33-934ed8ee378c"
   },
   "source": [
    "**Hint**\n",
    "\n",
    "Your first mission is to familiarize yourself with the **Books to Scrape** website. Navigate to [Books to Scrape](http://books.toscrape.com/) and explore the available books to understand their layout and structure. \n",
    "\n",
    "Next, think about how you can set parameters for your data extraction:\n",
    "\n",
    "- **Minimum Rating**: Focus on books with a rating of 4.0 and above.\n",
    "- **Maximum Price**: Filter for books priced up to £20.\n",
    "\n",
    "After reviewing the site, you can construct a plan for scraping relevant data. Pay attention to the details displayed for each book, including the title, price, rating, and availability. This will help you identify the correct HTML elements to target with your scraping script.\n",
    "\n",
    "Make sure to build your scraping URL and logic based on the patterns you observe in the HTML structure of the book listings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a83a0d-a742-49f6-985e-e27887cbf922",
   "metadata": {
    "id": "25a83a0d-a742-49f6-985e-e27887cbf922"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Best of luck! Immerse yourself in the world of books, and may the data be with you!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0",
   "metadata": {
    "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0"
   },
   "source": [
    "**Important Note**:\n",
    "\n",
    "In the fast-changing online world, websites often update and change their structures. When you try this lab, the **Books to Scrape** website might differ from what you expect.\n",
    "\n",
    "If you encounter issues due to these changes, like new rules or obstacles preventing data extraction, don’t worry! Get creative.\n",
    "\n",
    "You can choose another website that interests you and is suitable for scraping data. Options like Wikipedia, The New York Times, or even library databases are great alternatives. The main goal remains the same: extract useful data and enhance your web scraping skills while exploring a source of information you enjoy. This is your opportunity to practice and adapt to different web environments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40359eee-9cd7-4884-bfa4-83344c222305",
   "metadata": {
    "id": "40359eee-9cd7-4884-bfa4-83344c222305"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39b227aa-921d-4e8d-9819-ad4e6d6b36ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map the text rating class names to integer values\n",
    "RATING_MAP = {\n",
    "    'One': 1, \n",
    "    'Two': 2, \n",
    "    'Three': 3, \n",
    "    'Four': 4, \n",
    "    'Five': 5\n",
    "}\n",
    "\n",
    "def get_numeric_rating(tag):\n",
    "    \"\"\"\n",
    "    Extracts the rating class from the HTML tag and converts it to an integer.\n",
    "    Example: 'star-rating Three' -> 3\n",
    "    \"\"\"\n",
    "    # Ratings are stored in a class attribute, e.g., class=\"star-rating Three\"\n",
    "    rating_class = tag.find('p')['class'][-1] if tag.find('p') else 'Zero'\n",
    "    return RATING_MAP.get(rating_class, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "36a001ed-9643-4010-95c6-ce3127bd7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books(min_rating: int, max_price: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scrapes book data from Books to Scrape, filters the results, and returns a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - min_rating (int): The minimum acceptable rating (1 to 5).\n",
    "    - max_price (float): The maximum acceptable price.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A filtered DataFrame of book data.\n",
    "    \"\"\"\n",
    "    BASE_URL =\"https://books.toscrape.com/catalogue/\"\n",
    "    current_page_url = BASE_URL + 'page-1.html'\n",
    "    all_books_data = []\n",
    "    page_count = 0\n",
    "\n",
    "    while current_page_url:\n",
    "        page_count += 1\n",
    "        print(f\"Scraping Page {page_count}: {current_page_url}\")\n",
    "\n",
    "        try:\n",
    "            response = requests.get(current_page_url, timeout=10)\n",
    "            response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching page {current_page_url}: {e}\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Select all book article containers on the page\n",
    "        book_articles = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "        if not book_articles:\n",
    "            print(\"No more books found on this page. Stopping.\")\n",
    "            break\n",
    "        for article in book_articles:\n",
    "            # 1. Title\n",
    "            title_tag = article.find('h3').find('a')\n",
    "            title = title_tag['title'] if title_tag else 'N/A'\n",
    "            detail_link = title_tag['href']\n",
    "            \n",
    "            # Construct the absolute detail URL\n",
    "            detail_url = requests.compat.urljoin(BASE_URL, detail_link)\n",
    "\n",
    "            # 2. Price (Extract, clean, and convert to float)\n",
    "            price_tag = article.find(\"p\", attrs={\"class\":\"price_color\"})\n",
    "            price_match = re.search(r'[\\d\\.]+', price_tag.text) if price_tag else None\n",
    "            price_float = float(price_match.group(0)) if price_match else 0.0\n",
    "            \n",
    "            # 3. Rating (Convert class name to integer)\n",
    "            rating = get_numeric_rating(article)\n",
    "\n",
    "            # 4. Availability\n",
    "            availability = article.find(\"p\", attrs={\"class\":\"instock availability\"}).get_text().strip() if article.find(\"p\", attrs={\"class\":\"instock availability\"}) else 'N/A'\n",
    "            \n",
    "            # --- STAGE 2: Scrape Detail Page for Genre ---\n",
    "            genre = \"N/A\"\n",
    "            try:\n",
    "                detail_response = requests.get(detail_url, timeout=5)\n",
    "                detail_response.raise_for_status()\n",
    "                detail_soup = BeautifulSoup(detail_response.text, 'html.parser')\n",
    "                \n",
    "                # The category/genre is the second link in the breadcrumb list\n",
    "                breadcrumb_items = detail_soup.select('ul.breadcrumb li a')\n",
    "                if len(breadcrumb_items) > 1:\n",
    "                    # Index 0 is 'Home', Index 1 is the Category/Genre\n",
    "                    genre = breadcrumb_items[1].text\n",
    "                \n",
    "                #Getting description\n",
    "                descrip=detail_soup.select('article.product_page p')\n",
    "                description=descrip\n",
    "\n",
    "                # Getting UPC\n",
    "                get_upc=detail_soup.select(\"tr td\")\n",
    "                upc=get_upc[0]\n",
    "                # Be polite: wait a small amount of time between detail page requests\n",
    "                time.sleep(0.1) \n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"    Error fetching detail page {detail_url}. Genre set to 'Error'.\")\n",
    "                # print(f\"    Error: {e}\") # Uncomment for debugging\n",
    "                genre = \"Error\"\n",
    "\n",
    "            book_info = {\n",
    "                'Title': title,\n",
    "                'Price': price_float,\n",
    "                'Rating': rating,\n",
    "                'Availability': availability,\n",
    "                'Genre': genre,\n",
    "                \"Description\": description,\n",
    "                \"UPC\": upc\n",
    "            }\n",
    "            all_books_data.append(book_info)\n",
    "            \n",
    "        # Find the next page link for pagination\n",
    "        next_button = soup.find('li', class_='next')\n",
    "        if next_button:\n",
    "            # The 'href' is relative, so we append it to the base URL\n",
    "            next_url = next_button.find('a')['href']\n",
    "            # For the first page, the URL changes from index.html to page-2.html, \n",
    "            # so we ensure we prepend the base path correctly.\n",
    "            if 'index.html' in current_page_url:\n",
    "                current_page_url = BASE_URL + next_url\n",
    "                time.sleep(0.5)\n",
    "            else:\n",
    "                # If we are on page-X.html, we need to join the relative path correctly\n",
    "                current_page_url = requests.compat.urljoin(current_page_url, next_url)\n",
    "                \n",
    "            \n",
    "        else:\n",
    "            current_page_url = None\n",
    "\n",
    "    print(\"\\n--- Scraping Complete. Starting Filtering. ---\")\n",
    "\n",
    "    # Create the DataFrame from the collected data\n",
    "    df = pd.DataFrame(all_books_data)\n",
    "    \n",
    "    # --- Filtering Logic ---\n",
    "    # Filter by minimum rating & by maximum price\n",
    "    df_filtered = df[(df['Rating'] >= min_rating) & (df['Price'] <= max_price)]\n",
    "    return df_filtered\n",
    "    print(f\"Total books scraped: {len(df)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6cea3-52ff-447a-9fde-c2e0c6863c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3e0d56c7-5e7c-4c1e-a271-17a8e53ccd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Page 1: https://books.toscrape.com/catalogue/page-1.html\n",
      "Scraping Page 2: https://books.toscrape.com/catalogue/page-2.html\n",
      "Scraping Page 3: https://books.toscrape.com/catalogue/page-3.html\n",
      "Scraping Page 4: https://books.toscrape.com/catalogue/page-4.html\n",
      "Scraping Page 5: https://books.toscrape.com/catalogue/page-5.html\n",
      "Scraping Page 6: https://books.toscrape.com/catalogue/page-6.html\n",
      "Scraping Page 7: https://books.toscrape.com/catalogue/page-7.html\n",
      "Scraping Page 8: https://books.toscrape.com/catalogue/page-8.html\n",
      "Scraping Page 9: https://books.toscrape.com/catalogue/page-9.html\n",
      "Scraping Page 10: https://books.toscrape.com/catalogue/page-10.html\n",
      "Scraping Page 11: https://books.toscrape.com/catalogue/page-11.html\n",
      "Scraping Page 12: https://books.toscrape.com/catalogue/page-12.html\n",
      "Scraping Page 13: https://books.toscrape.com/catalogue/page-13.html\n",
      "Scraping Page 14: https://books.toscrape.com/catalogue/page-14.html\n",
      "Scraping Page 15: https://books.toscrape.com/catalogue/page-15.html\n",
      "Scraping Page 16: https://books.toscrape.com/catalogue/page-16.html\n",
      "Scraping Page 17: https://books.toscrape.com/catalogue/page-17.html\n",
      "Scraping Page 18: https://books.toscrape.com/catalogue/page-18.html\n",
      "Scraping Page 19: https://books.toscrape.com/catalogue/page-19.html\n",
      "Scraping Page 20: https://books.toscrape.com/catalogue/page-20.html\n",
      "Scraping Page 21: https://books.toscrape.com/catalogue/page-21.html\n",
      "Scraping Page 22: https://books.toscrape.com/catalogue/page-22.html\n",
      "Scraping Page 23: https://books.toscrape.com/catalogue/page-23.html\n",
      "Scraping Page 24: https://books.toscrape.com/catalogue/page-24.html\n",
      "Scraping Page 25: https://books.toscrape.com/catalogue/page-25.html\n",
      "Scraping Page 26: https://books.toscrape.com/catalogue/page-26.html\n",
      "Scraping Page 27: https://books.toscrape.com/catalogue/page-27.html\n",
      "Scraping Page 28: https://books.toscrape.com/catalogue/page-28.html\n",
      "Scraping Page 29: https://books.toscrape.com/catalogue/page-29.html\n",
      "    Error fetching detail page https://books.toscrape.com/catalogue/pride-and-prejudice_437/index.html. Genre set to 'Error'.\n",
      "Scraping Page 30: https://books.toscrape.com/catalogue/page-30.html\n",
      "Scraping Page 31: https://books.toscrape.com/catalogue/page-31.html\n",
      "Scraping Page 32: https://books.toscrape.com/catalogue/page-32.html\n",
      "Scraping Page 33: https://books.toscrape.com/catalogue/page-33.html\n",
      "Scraping Page 34: https://books.toscrape.com/catalogue/page-34.html\n",
      "Scraping Page 35: https://books.toscrape.com/catalogue/page-35.html\n",
      "Scraping Page 36: https://books.toscrape.com/catalogue/page-36.html\n",
      "Scraping Page 37: https://books.toscrape.com/catalogue/page-37.html\n",
      "Scraping Page 38: https://books.toscrape.com/catalogue/page-38.html\n",
      "Scraping Page 39: https://books.toscrape.com/catalogue/page-39.html\n",
      "Scraping Page 40: https://books.toscrape.com/catalogue/page-40.html\n",
      "Scraping Page 41: https://books.toscrape.com/catalogue/page-41.html\n",
      "Scraping Page 42: https://books.toscrape.com/catalogue/page-42.html\n",
      "Scraping Page 43: https://books.toscrape.com/catalogue/page-43.html\n",
      "Scraping Page 44: https://books.toscrape.com/catalogue/page-44.html\n",
      "Scraping Page 45: https://books.toscrape.com/catalogue/page-45.html\n",
      "Scraping Page 46: https://books.toscrape.com/catalogue/page-46.html\n",
      "Scraping Page 47: https://books.toscrape.com/catalogue/page-47.html\n",
      "Scraping Page 48: https://books.toscrape.com/catalogue/page-48.html\n",
      "Scraping Page 49: https://books.toscrape.com/catalogue/page-49.html\n",
      "Scraping Page 50: https://books.toscrape.com/catalogue/page-50.html\n",
      "\n",
      "--- Scraping Complete. Starting Filtering. ---\n"
     ]
    }
   ],
   "source": [
    "# Define your filtering parameters\n",
    "MIN_RATING_THRESHOLD = 4  # Only show books rated 4 stars or higher\n",
    "MAX_PRICE_THRESHOLD = 20.00 # Only show books priced at £20.00 or less\n",
    "\n",
    "# Run the scraper\n",
    "filtered_df = scrape_books(min_rating=MIN_RATING_THRESHOLD, max_price=MAX_PRICE_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6abbfc64-07bd-4329-96c6-6a507b5a429d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m filtered_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_df' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa9683c4-55a0-4041-8089-57e0d13c3827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Light in the Attic'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "product[0].find(\"img\")[\"alt\"]\n",
    "def get_brand(item):\n",
    "    brand_name=item.find(\"img\")[\"alt\"]\n",
    "    return brand_name\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4443200a-6f05-4460-81a3-155dea78f678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'51.77'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "product[0].find(\"p\", attrs={\"class\":\"price_color\"}).get_text().replace(\"£\",\"\")\n",
    "def get_price(item):\n",
    "    brand_price=item.find(\"p\", attrs={\"class\":\"price_color\"}).get_text().replace(\"£\",\"\")\n",
    "    return brand_price\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b7d94050-f6da-4f52-9cdc-5778f10ca6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In stock'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product[0].find(\"p\", attrs={\"class\":\"instock availability\"}).get_text().strip()\n",
    "def get_avail(item):\n",
    "    brand_avail=item.find(\"p\", attrs={\"class\":\"instock availability\"}).get_text().strip()\n",
    "    return brand_avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b5e9c6a5-e712-411f-9078-a9152d1bff64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product[0].find(\"p\")[\"class\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fc8ae-680d-4002-b815-13ae39b5ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The second step involves searching deep into the particular page for each item using the link filtered from the main or general page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1a963-63ac-4991-b9ae-a59ba6394d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prod in product():\n",
    "    prod.find(\"img\")[\"alt\"]\n",
    "    product[0].find(\"p\", attrs={\"class\":\"price_color\"}).get_text().replace(\"£\",\"\")\n",
    "    product[0].find(\"p\", attrs={\"class\":\"instock availability\"}).get_text().strip()\n",
    "    partial=product[0].find(\"a\")[\"href\"]\n",
    "    domain=\"https://books.toscrape.com/\"\n",
    "    url=domain+partial"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
